{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4872fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunnyhong/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665c0693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TrainCfg:\n",
    "    model_name: str = \"roberta-base\"\n",
    "\n",
    "    max_length: int = 512\n",
    "    train_batch_size: int = 4\n",
    "    valid_batch_size: int = 4\n",
    "    learning_rate: float = 2e-5\n",
    "    epochs: int = 10\n",
    "    seed: int = 42\n",
    "\n",
    "    # Paths (Kaggle-compatible structure)\n",
    "    train_path: str = \"data/lmsys-chatbot-arena/train.csv\"\n",
    "    train_path_extend: str = \"data/lmsys-33k-deduplicated.csv\"\n",
    "\n",
    "    test_path: str = \"data/lmsys-chatbot-arena/test.csv\"\n",
    "    sub_path: str = \"data/ours_submission.csv\"\n",
    "\n",
    "    device: torch.device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "cfg = TrainCfg()\n",
    "set_seed(cfg.seed)\n",
    "print(\"Using device:\", cfg.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79950df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "import ast\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Robustly convert the CSV field to plain text.\n",
    "    Handles:\n",
    "      - None / NaN\n",
    "      - actual Python lists\n",
    "      - stringified lists like '[\"hello\", \"world\"]'\n",
    "      - malformed '[...]' that can't be parsed (falls back gracefully)\n",
    "    \"\"\"\n",
    "    # 1. Missing values\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if isinstance(text, float) and np.isnan(text):\n",
    "        return \"\"\n",
    "\n",
    "    if isinstance(text, list):\n",
    "        return \" \".join(\"\" if t is None else str(t) for t in text)\n",
    "\n",
    "    s = str(text)\n",
    "\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return s.strip(\"[]\")\n",
    "\n",
    "        if isinstance(parsed, list):\n",
    "            return \" \".join(\"\" if t is None else str(t) for t in parsed)\n",
    "        else:\n",
    "            return str(parsed)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "class LMSYSDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # Convert to records for speed\n",
    "        self.data = self.df[[\"prompt\", \"response_a\", \"response_b\"]].to_dict(\"records\")\n",
    "\n",
    "        # Pre-compute labels\n",
    "        if not self.is_test:\n",
    "            self.labels = []\n",
    "            for _, row in self.df.iterrows():\n",
    "                if row[\"winner_model_a\"] == 1:\n",
    "                    label = 0\n",
    "                elif row[\"winner_model_b\"] == 1:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 2\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        prompt = row[\"prompt\"]\n",
    "        response_a = row[\"response_a\"]\n",
    "        response_b = row[\"response_b\"]\n",
    "\n",
    "        if not self.is_test:\n",
    "            if row[\"winner_model_a\"] == 1:\n",
    "                label = 0   # A wins\n",
    "            elif row[\"winner_model_b\"] == 1:\n",
    "                label = 1   # B wins\n",
    "            else:\n",
    "                label = 2   # tie\n",
    "        else:\n",
    "            label = -1  # unused\n",
    "\n",
    "        # ----- Data augmentation: random swap A/B -----\n",
    "        if not self.is_test:\n",
    "            # 50% chance to swap\n",
    "            if random.random() < 0.5:\n",
    "                response_a, response_b = response_b, response_a\n",
    "                if label == 0:\n",
    "                    label = 1\n",
    "                elif label == 1:\n",
    "                    label = 0\n",
    "        \n",
    "        encoded = self.tokenizer(\n",
    "            prompt,\n",
    "            response_a + self.tokenizer.eos_token + response_b,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "        if not self.is_test:\n",
    "            item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = F.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "    num_classes = probs.shape[1]\n",
    "    labels = np.array(labels, dtype=int)\n",
    "    labels_oh = np.eye(num_classes)[labels]\n",
    "\n",
    "    return {\"log_loss\": log_loss(labels_oh, probs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf85baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Original train shape: (57477, 9)\n",
      "Original extended train shape : (21187, 9)\n",
      "Original test shape: (3, 4)\n",
      "train: Dropping 26 empty rows\n",
      "After cleaning, train shape: (57451, 9)\n",
      "After cleaning, test shape: (3, 4)\n",
      "train_ext: Dropping 21 empty rows\n",
      "After cleaning, train_ext shape: (21166, 9)\n",
      "Concatenating main + extended train...\n",
      "Final combined train shape: (78617, 9)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def strip_surrogates(text: str) -> str:\n",
    "    \"\"\"Remove characters that cannot be encoded in UTF-8 (surrogates etc).\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    return text.encode(\"utf-8\", \"replace\").decode(\"utf-8\")\n",
    "\n",
    "def strip_control_chars(s: str) -> str:\n",
    "    \"\"\"Remove ASCII control chars except \\n and \\t.\"\"\"\n",
    "    return re.sub(r\"[\\x00-\\x08\\x0B-\\x1F\\x7F]\", \"\", s)\n",
    "\n",
    "def safe_literal_list(text: str):\n",
    "    \"\"\"Safely parse stringified list like '[\"a\", \"b\"]', else return None.\"\"\"\n",
    "    if text.startswith(\"[\") and text.endswith(\"]\"):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(text)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def clean_text(x):\n",
    "    \"\"\"Complete cleaning pipeline.\"\"\"\n",
    "    # None / NaN\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    if isinstance(x, float) and np.isnan(x):\n",
    "        return \"\"\n",
    "\n",
    "    if isinstance(x, list):\n",
    "        return \" \".join(strip_surrogates(strip_control_chars(str(t))) for t in x)\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    parsed_list = safe_literal_list(s)\n",
    "    if parsed_list is not None:\n",
    "        return \" \".join(strip_surrogates(strip_control_chars(str(t))) for t in parsed_list)\n",
    "\n",
    "    # Strip unicode surrogates and control characters\n",
    "    s = strip_surrogates(s)\n",
    "    s = strip_control_chars(s)\n",
    "\n",
    "    return s\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "train_df = pd.read_csv(cfg.train_path)\n",
    "train_ext_df = pd.read_csv(cfg.train_path_extend)\n",
    "test_df = pd.read_csv(cfg.test_path)\n",
    "\n",
    "print(\"Original train shape:\", train_df.shape)\n",
    "print(\"Original extended train shape :\", train_ext_df.shape)\n",
    "print(\"Original test shape:\", test_df.shape)\n",
    "\n",
    "dfs = {\"train\": train_df, \"test\": test_df, \"train_ext\": train_ext_df}\n",
    "\n",
    "for df_name, df in dfs.items():\n",
    "    df.dropna(subset=[\"prompt\", \"response_a\", \"response_b\"], inplace=True)\n",
    "    for col in [\"prompt\", \"response_a\", \"response_b\"]:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "\n",
    "    mask_empty = (\n",
    "        df[\"prompt\"].str.strip().eq(\"\") |\n",
    "        df[\"response_a\"].str.strip().eq(\"\") |\n",
    "        df[\"response_b\"].str.strip().eq(\"\")\n",
    "    )\n",
    "    to_drop = mask_empty.sum()\n",
    "    if to_drop > 0:\n",
    "        print(f\"{df_name}: Dropping {to_drop} empty rows\")\n",
    "        df.drop(df[mask_empty].index, inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"After cleaning, {df_name} shape:\", df.shape)\n",
    "\n",
    "print(\"Concatenating main + extended train...\")\n",
    "train_df = pd.concat([train_df, train_ext_df], ignore_index=True)\n",
    "print(\"Final combined train shape:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321c0f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  As an AI, I don't have personal beliefs or opi...               1   \n",
       "1  A marriage license and a marriage certificate ...               0   \n",
       "2  Function calling is the process of invoking a ...               0   \n",
       "3  When building a classifier for a very rare cat...               1   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fbe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer & model...\n",
      "Train samples: 51705, Val samples: 5746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28416\\628969652.py:52: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38781' max='38781' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38781/38781 1:29:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.095900</td>\n",
       "      <td>1.097005</td>\n",
       "      <td>1.097114</td>\n",
       "      <td>37.673000</td>\n",
       "      <td>152.523000</td>\n",
       "      <td>38.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.094900</td>\n",
       "      <td>1.096594</td>\n",
       "      <td>1.096550</td>\n",
       "      <td>55.778400</td>\n",
       "      <td>103.015000</td>\n",
       "      <td>25.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.099400</td>\n",
       "      <td>1.097170</td>\n",
       "      <td>1.097041</td>\n",
       "      <td>54.686000</td>\n",
       "      <td>105.073000</td>\n",
       "      <td>26.277000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer & model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "\n",
    "# Ensure pad_token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Split data\n",
    "train_split, val_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    random_state=cfg.seed,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Initialize Datasets (Now fast because we don't tokenize yet)\n",
    "train_dataset = LMSYSDataset(train_split, tokenizer, cfg.max_length, is_test=False)\n",
    "valid_dataset = LMSYSDataset(val_split, tokenizer, cfg.max_length, is_test=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(valid_dataset)}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    num_labels=3,\n",
    ")\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Use DataCollator to pad batches dynamically to the longest sequence in the BATCH\n",
    "# (instead of padding everything to max_length=1024, which wastes GPU memory)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"./outputs/{cfg.model_name.replace('/', '_')}_finetuned\",\n",
    "    num_train_epochs=cfg.epochs,\n",
    "    per_device_train_batch_size=cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=cfg.valid_batch_size,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"log_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\",\n",
    "    fp16=True, # Recommended for T4/P100 GPUs (Kaggle) to save memory/speed up\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b03b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainCfg(\n",
    "    model_name=\"distilroberta-base\", \n",
    "    epochs=10,\n",
    "    learning_rate=3e-5, \n",
    "    train_batch_size=64, \n",
    "    valid_batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ea0c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer & model...\n",
      "Train samples: 51705, Val samples: 5746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2472852/3441798207.py:52: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5137' max='16160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5137/16160 42:39 < 1:31:34, 2.01 it/s, Epoch 6.36/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.084900</td>\n",
       "      <td>1.078510</td>\n",
       "      <td>1.078511</td>\n",
       "      <td>23.541100</td>\n",
       "      <td>244.084000</td>\n",
       "      <td>3.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.072300</td>\n",
       "      <td>1.075383</td>\n",
       "      <td>1.075381</td>\n",
       "      <td>25.592300</td>\n",
       "      <td>224.520000</td>\n",
       "      <td>3.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.041600</td>\n",
       "      <td>1.060189</td>\n",
       "      <td>1.060189</td>\n",
       "      <td>23.030900</td>\n",
       "      <td>249.490000</td>\n",
       "      <td>3.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.011400</td>\n",
       "      <td>1.063650</td>\n",
       "      <td>1.063648</td>\n",
       "      <td>24.532900</td>\n",
       "      <td>234.216000</td>\n",
       "      <td>3.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>1.158816</td>\n",
       "      <td>1.158819</td>\n",
       "      <td>24.126700</td>\n",
       "      <td>238.159000</td>\n",
       "      <td>3.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.893700</td>\n",
       "      <td>1.256071</td>\n",
       "      <td>1.256077</td>\n",
       "      <td>24.068300</td>\n",
       "      <td>238.737000</td>\n",
       "      <td>3.739000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 63\u001b[0m\n\u001b[1;32m     52\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     53\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     54\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator, \u001b[38;5;66;03m# <--- Added this\u001b[39;00m\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/accelerate/accelerator.py:2848\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2848\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NLP_final/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer & model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "\n",
    "# Ensure pad_token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Split data\n",
    "train_split, val_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    random_state=cfg.seed,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Initialize Datasets (Now fast because we don't tokenize yet)\n",
    "train_dataset = LMSYSDataset(train_split, tokenizer, cfg.max_length, is_test=False)\n",
    "valid_dataset = LMSYSDataset(val_split, tokenizer, cfg.max_length, is_test=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(valid_dataset)}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    num_labels=3,\n",
    ")\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Use DataCollator to pad batches dynamically to the longest sequence in the BATCH\n",
    "# (instead of padding everything to max_length=1024, which wastes GPU memory)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"./outputs/{cfg.model_name.replace('/', '_')}_finetuned\",\n",
    "    num_train_epochs=cfg.epochs,\n",
    "    per_device_train_batch_size=cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=cfg.valid_batch_size,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"log_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\",\n",
    "    fp16=True, # Recommended for T4/P100 GPUs (Kaggle) to save memory/speed up\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # <--- Added this\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainCfg(\n",
    "    model_name=\"distilroberta-base\", \n",
    "    max_length=1024,\n",
    "    learning_rate=3e-5, \n",
    "    train_batch_size=16, \n",
    "    valid_batch_size=16\n",
    ")\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e6c3c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference with A/B swap TTA...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to: data/ours_submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.347363</td>\n",
       "      <td>0.347363</td>\n",
       "      <td>0.305274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.347366</td>\n",
       "      <td>0.347366</td>\n",
       "      <td>0.305269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.347362</td>\n",
       "      <td>0.347362</td>\n",
       "      <td>0.305276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.347363        0.347363    0.305274\n",
       "1   211333        0.347366        0.347366    0.305269\n",
       "2  1233961        0.347362        0.347362    0.305276"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting inference with A/B swap TTA...\")\n",
    "\n",
    "# 1. Normal test dataset: (prompt, A, B)\n",
    "test_ds_normal = LMSYSDataset(test_df, tokenizer, cfg.max_length, is_test=True)\n",
    "\n",
    "# 2. Swapped test dataset: (prompt, B, A)\n",
    "test_df_swapped = test_df.copy()\n",
    "test_df_swapped[[\"response_a\", \"response_b\"]] = test_df_swapped[[\"response_b\", \"response_a\"]]\n",
    "test_ds_swapped = LMSYSDataset(test_df_swapped, tokenizer, cfg.max_length, is_test=True)\n",
    "\n",
    "# Predict\n",
    "preds_normal = trainer.predict(test_ds_normal).predictions\n",
    "preds_swapped = trainer.predict(test_ds_swapped).predictions\n",
    "\n",
    "probs_normal = F.softmax(torch.tensor(preds_normal), dim=-1).numpy()\n",
    "probs_swapped = F.softmax(torch.tensor(preds_swapped), dim=-1).numpy()\n",
    "\n",
    "# For swapped, model's \"class 0\" means \"first response wins\" which is B in original,\n",
    "# and \"class 1\" means \"second response wins\" which is A in original.\n",
    "# So we need to swap back the first two probability columns.\n",
    "probs_swapped_fixed = np.zeros_like(probs_swapped)\n",
    "probs_swapped_fixed[:, 0] = probs_swapped[:, 1]  # B->A\n",
    "probs_swapped_fixed[:, 1] = probs_swapped[:, 0]  # A->B\n",
    "probs_swapped_fixed[:, 2] = probs_swapped[:, 2]  # tie unchanged\n",
    "\n",
    "# Ensemble\n",
    "final_probs = (probs_normal + probs_swapped_fixed) / 2.0\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": test_df[\"id\"].values,\n",
    "        \"winner_model_a\": final_probs[:, 0],\n",
    "        \"winner_model_b\": final_probs[:, 1],\n",
    "        \"winner_tie\": final_probs[:, 2],\n",
    "    }\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(cfg.sub_path), exist_ok=True)\n",
    "submission.to_csv(cfg.sub_path, index=False)\n",
    "print(\"Saved submission to:\", cfg.sub_path)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
